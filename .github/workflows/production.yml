name: API Production Deployment

on:
  workflow_dispatch:
    inputs:
      image_tag:
        description: 'Docker image tag to deploy'
        required: true
        default: 'latest'
        type: string
      confirm_deployment:
        description: 'Confirm production deployment'
        required: true
        type: boolean
  push:
    tags:
      - 'v*'
      - 'release-*'
  pull_request:
    branches: [ main ]

env:
  REGISTRY: cerit.io
  IMAGE_NAME: mol-view-stories/mvs-api

jobs:
  build-and-push:
    runs-on: ubuntu-latest
    outputs:
      image_digest: ${{ steps.build_and_push.outputs.digest }}
      docker_version: ${{ steps.release-version.outputs.docker_version }}
      version: ${{ steps.release-version.outputs.version }}
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Fetch all history for git describe
      
      - name: Get release version
        id: release-version
        run: |
          # For PR deployments, use the specified dev image tag
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            VERSION="v1.0.0-dev.2"
            echo "Using PR test image tag: $VERSION"
          # Always try to get the tag name first (for tag pushes)
          elif [ "${{ github.event_name }}" = "push" ]; then
            VERSION="${{ github.ref_name }}"
            echo "Using tag from push event: $VERSION"
          else
            # For manual deployments, use provided image_tag or get latest tag
            if [ "${{ inputs.image_tag }}" != "latest" ]; then
              VERSION="${{ inputs.image_tag }}"
              echo "Using provided image_tag: $VERSION"
            else
              VERSION=$(git describe --abbrev=0 --tags 2>/dev/null || echo "latest")
              echo "Using latest tag from git describe: $VERSION"
            fi
          fi
          
          # Validate version format (basic check)
          if [[ -z "$VERSION" ]]; then
            echo "Warning: Version is empty, using fallback"
            VERSION="latest"
          fi
          
          # Sanitize version for Docker tags (replace slashes and other invalid chars)
          DOCKER_VERSION=$(echo "$VERSION" | sed 's/[^a-zA-Z0-9._-]/-/g')
          if [[ "$DOCKER_VERSION" != "$VERSION" ]]; then
            echo "Warning: Sanitized version for Docker: '$VERSION' -> '$DOCKER_VERSION'"
          fi
          
          echo "version=$VERSION" >> $GITHUB_OUTPUT
          echo "docker_version=$DOCKER_VERSION" >> $GITHUB_OUTPUT
          echo "Release version: $VERSION"
          echo "Docker version: $DOCKER_VERSION"
          
          # Fail the build if we can't determine a reasonable version
          if [[ "$VERSION" == "latest" && "${{ github.event_name }}" == "push" ]]; then
            echo "Error: Could not determine version for tag push"
            exit 1
          fi

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r api/requirements.txt

      - name: Run tests
        run: |
          echo "Running tests..."
          # python -m pytest api/tests/

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ secrets.CERIT_REGISTRY_USERNAME }}
          password: ${{ secrets.CERIT_REGISTRY_PASSWORD }}

      - name: Test Docker login
        run: |
          echo "=== Testing Docker login ==="
          echo "Testing docker login to ${{ env.REGISTRY }}"
          
          if docker login ${{ env.REGISTRY }} -u "${{ secrets.CERIT_REGISTRY_USERNAME }}" -p "${{ secrets.CERIT_REGISTRY_PASSWORD }}" 2>&1 | grep -q "Login Succeeded"; then
            echo "✓ Docker login successful"
          else
            echo "✗ Docker login failed"
            exit 1
          fi

      - name: Build and push Docker image
        id: build_and_push
        uses: docker/build-push-action@v5
        with:
          context: ./api
          push: true
          tags: |
            ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ steps.release-version.outputs.docker_version }}
            ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest
          platforms: linux/amd64
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Verify pushed image
        run: |
          echo "Pushed digest: ${{ steps.build_and_push.outputs.digest }}"
          docker pull ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}@${{ steps.build_and_push.outputs.digest }}

  deploy-production:
    needs: build-and-push
    runs-on: ubuntu-latest
    if: github.event_name == 'push' || inputs.confirm_deployment == true
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'latest'

      - name: Configure kubectl
        run: |
          KCONF='${{ secrets.K8S_CONTEXT }}'
          if echo "$KCONF" | base64 -d >/dev/null 2>&1; then
            echo "Detected base64-encoded kubeconfig"
            echo "$KCONF" | base64 -d > kubeconfig
          else
            echo "Using raw kubeconfig"
            printf "%s" "$KCONF" > kubeconfig
          fi
          echo "KUBECONFIG=$PWD/kubeconfig" >> "$GITHUB_ENV"

      - name: Deploy to production
        run: |
          export KUBECONFIG=kubeconfig
          
          echo "=== Production Deployment ==="
          echo "Image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ needs.build-and-push.outputs.docker_version }}"
          echo "Namespace: mol-view-stories-ns"
          
          # Check if production deployment exists
          if kubectl get deployment/mol-view-stories-api -n mol-view-stories-ns >/dev/null 2>&1; then
            echo "Production deployment exists, updating image..."
            # Apply latest production deployment spec to ensure strategy, probes, lifecycle are up to date
            kubectl apply -f api/deploy.yaml
            # Update deployment with new image
            kubectl set image deployment/mol-view-stories-api \
              mol-view-stories-api-container=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ needs.build-and-push.outputs.docker_version }} \
              -n mol-view-stories-ns
            
            # Set MinIO environment variables for production
            echo "Setting MinIO environment variables for production..."
            kubectl set env deployment/mol-view-stories-api \
              -n mol-view-stories-ns \
              -c mol-view-stories-api-container \
              MINIO_ENDPOINT="${{ secrets.MINIO_PROD_URL }}" \
              MINIO_ACCESS_KEY="${{ secrets.MINIO_PROD_USERNAME }}" \
              MINIO_SECRET_KEY="${{ secrets.MINIO_PROD_PASSWORD }}" \
              MINIO_BUCKET="mol-view-stories"
            
            # Restart deployment to ensure new image is pulled
            kubectl rollout restart deployment/mol-view-stories-api -n mol-view-stories-ns
            
            # Monitor rollout with detailed logging
            echo "Starting rollout monitoring..."
            timeout 600s bash -c '
              while true; do
                echo "=== Rollout Status Check $(date) ==="
                kubectl rollout status deployment/mol-view-stories-api -n mol-view-stories-ns --timeout=30s || {
                  echo "Rollout status check timed out, investigating..."
                  echo "Current deployment summary:"
                  kubectl get deployment/mol-view-stories-api -n mol-view-stories-ns -o wide
                  echo "Deployment details (conditions):"
                  kubectl get deployment/mol-view-stories-api -n mol-view-stories-ns -o yaml | grep -A 10 -B 10 -E "(replicas|conditions|message)"
                  echo "Current pods:"
                  kubectl get pods -n mol-view-stories-ns -l deployment-id=mol-view-stories-api -o wide || true
                  echo "ReplicaSet status:"
                  kubectl get rs -n mol-view-stories-ns -l deployment-id=mol-view-stories-api -o wide || true
                  echo "Recent events:"
                  kubectl get events -n mol-view-stories-ns --sort-by=.lastTimestamp | tail -20 || true
                  continue
                }
                echo "Rollout completed successfully!"
                break
              done
            ' || {
              echo "ERROR: Deployment timed out after 10 minutes"
              echo "Final deployment state:"
              kubectl get deployment/mol-view-stories-api -n mol-view-stories-ns -o yaml
              kubectl get pods -n mol-view-stories-ns -l deployment-id=mol-view-stories-api -o wide
              kubectl describe deployment/mol-view-stories-api -n mol-view-stories-ns
              exit 1
            }
          else
            echo "Production deployment does not exist, creating new production deployment..."
            # Create a new production deployment using the deployment file with proper image replacement
            kubectl apply -f api/deploy.yaml
            
            # Set MinIO environment variables for production
            echo "Setting MinIO environment variables for production..."
            kubectl set env deployment/mol-view-stories-api \
              -n mol-view-stories-ns \
              -c mol-view-stories-api-container \
              MINIO_ENDPOINT="${{ secrets.MINIO_PROD_URL }}" \
              MINIO_ACCESS_KEY="${{ secrets.MINIO_PROD_USERNAME }}" \
              MINIO_SECRET_KEY="${{ secrets.MINIO_PROD_PASSWORD }}" \
              MINIO_BUCKET="mol-view-stories"
            
            # Wait for rollout to complete with monitoring
            echo "Waiting for new deployment to become ready..."
            kubectl rollout status deployment/mol-view-stories-api -n mol-view-stories-ns --timeout=600s || {
              echo "ERROR: New deployment failed to become ready"
              kubectl get deployment/mol-view-stories-api -n mol-view-stories-ns -o yaml
              kubectl get pods -n mol-view-stories-ns -l deployment-id=mol-view-stories-api -o wide
              kubectl describe deployment/mol-view-stories-api -n mol-view-stories-ns
              exit 1
            }
          fi
          
          echo "✓ Production deployment completed successfully"

      - name: Health check
        run: |
          export KUBECONFIG=kubeconfig
          echo "Performing comprehensive health check..."
          
          # Wait for deployment to be available
          echo "Waiting for deployment to be available..."
          kubectl wait --for=condition=available deployment/mol-view-stories-api -n mol-view-stories-ns --timeout=600s || {
            echo "ERROR: Deployment not available after 10 minutes"
            kubectl get deployment/mol-view-stories-api -n mol-view-stories-ns -o yaml
            exit 1
          }

          # Verify all pods are ready
          echo "Verifying all pods are ready and healthy..."
          # Get current pods (may change during loop, so re-fetch each time)
          for i in {1..3}; do
            READY_PODS=$(kubectl get pods -n mol-view-stories-ns -l deployment-id=mol-view-stories-api --field-selector=status.phase=Running -o jsonpath='{.items[*].metadata.name}' 2>/dev/null || echo "")
            if [[ -z "$READY_PODS" ]]; then
              echo "No running pods found on attempt $i, waiting..."
              sleep 5
              continue
            fi
            break
          done

          for pod in $READY_PODS; do
            echo "Checking pod: $pod"
            # Skip if pod no longer exists (normal during rolling updates)
            if ! kubectl get pod/$pod -n mol-view-stories-ns >/dev/null 2>&1; then
              echo "Pod $pod no longer exists, skipping (normal during rolling update)"
              continue
            fi
            
            kubectl wait --for=condition=ready pod/$pod -n mol-view-stories-ns --timeout=60s || {
              echo "ERROR: Pod $pod not ready after 60s"
              kubectl describe pod $pod -n mol-view-stories-ns || true
              kubectl logs $pod -n mol-view-stories-ns --tail=50 || true
              # Don't exit on individual pod failure during rolling update
              echo "WARNING: Continuing despite pod $pod readiness issue"
            }
          done

      - name: Verify deployment
        run: |
          export KUBECONFIG=kubeconfig
          kubectl get pods -n mol-view-stories-ns -l deployment-id=mol-view-stories-api
          kubectl get services -n mol-view-stories-ns -l deployment-id=mol-view-stories-api

      - name: Deployment summary
        run: |
          echo "## Production Deployment Summary" >> $GITHUB_STEP_SUMMARY
          echo "- **Release Version**: ${{ needs.build-and-push.outputs.version }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Docker Tag**: ${{ needs.build-and-push.outputs.docker_version }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Registry**: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Deployment Time**: $(date)" >> $GITHUB_STEP_SUMMARY
          echo "- **Status**: ✅ Successfully deployed" >> $GITHUB_STEP_SUMMARY 